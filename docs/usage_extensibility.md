运行指南与可扩展性说明

本节汇总项目的运行方法和开发扩展提示，方便用户快速上手实验，并了解如何基于本框架进行功能拓展。

环境与运行准备

开发环境：确保已安装 Python 3.8+。建议创建虚拟环境，使用 pip install -r requirements.txt 安装依赖。本项目常用依赖包括 NumPy、PyTorch（用于DRL模型）、matplotlib（用于绘图）、yaml（读取配置）等。

目录检查：确认 configs/ 下存在所需配置文件，models/ 下存在DRL模型文件（若使用DRL策略），data/ 下有需要的数据集（若使用外部数据）。

GPU：若设备有NVIDIA GPU并安装CUDA，可在配置中 use_gpu: true 以启用PyTorch的GPU加速，这会显著提升DRL推理速度，尤其在大规模实例和复杂模型时。

运行命令概述

项目采用配置驱动运行，统一通过主程序入口加载配置执行对应任务。常用的运行命令示例：

运行单个实验：在仓库根目录执行:

python main.py --config configs/E1.yaml


上述命令将运行实验E1（随机移除策略），输出结果到 results/E1_random/（根据配置的 output_dir）。其他实验类似，更换配置文件名即可。若未指定 --config，程序可能使用默认配置或退出提示。

批量运行所有实验：为方便起见，可编写一个脚本或批处理命令:

for cfg in configs/E*.yaml; do
    python main.py --config $cfg
done


这将按照 E1.yaml ... E5.yaml 顺序运行所有实验。请注意逐个运行时可能耗时较长，尤其 E4/E5，请确保计算资源充足。

训练DRL模型：如 DRL 训练使用单独脚本:

python train_drl.py --config configs/train_DRL.yaml


运行后请等待训练完成（可能耗时较久，视配置的训练迭代数而定）。训练完会自动保存模型。如果需要中途停止训练，可手动中断，已保存模型视情况能部分工作（但策略可能不充分）。

如果没有 train_drl.py 脚本，则通过 main程序提供模式切换。例如:

python main.py --config configs/E5.yaml --mode train


需确保配置中标记了 train 模式选项，主程序能识别并进入训练逻辑。

自定义运行：用户也可以交互式地运行部分程序。例如在Python交互环境中导入模块，调用 hea.solve(instance) 来调试算法过程。不过对于正式实验，建议通过配置运行以确保结果记录完整一致。

运行日志与调试

在终端上，程序将输出与日志文件相同的信息（取决于日志级别）。可以实时观察进度和指标。如果某实验长时间无输出，可考虑调高日志级别以了解内部进展。

若发生错误，终端和日志都会给出堆栈信息。根据报错位置，可以打开相关源码进行修复。例如，某配置字段未读取，可能是拼写错误或代码未实现解析，需要相应修改。

调参可直接修改配置文件，然后重复运行命令。无须重编译或类似步骤。

可扩展性指南

本框架设计注重模块化，便于在现有基础上扩展新功能或适应新问题。以下给出几种常见扩展场景和方法：

1. 添加新移除策略

参考 Removal_Strategies.md 的说明，只需：

在 src/removal.py 中实现一个新的策略类，例如 GreedyRemoval(RemovalStrategy)，编写其 remove_tasks 方法逻辑。

将其映射到配置解析：例如在读取配置部分，加入：

if strategy_name == "greedy":
    strategy = GreedyRemoval(...)


在配置文件中使用 removal_strategy: "greedy" 进行测试。

编写少量测试实例验证新策略行为正确（如日志中输出其移除的任务集是否符合预期）。

通过这种方式，可以快速尝试论文中的其他移除算子或您自己的创意算法，与现有策略对比效果。

2. 更换/调整修复策略

目前实现的修复策略（重插入）是固定的启发式。如果想尝试不同的插入算法（例如插入同时考虑全局平衡等）：

修改或继承 src/repair.py 中的相应函数，实现新策略。

如需在配置中可选插入策略，可类似移除策略做接口封装。

注意更改插入策略后，对比实验时应保持其它变量不变，以衡量纯粹插入方法改进。

3. 扩展到新问题类型

如果要将本框架应用到不同但相关的优化问题（例如从车辆路径扩展到带时间窗的调度问题）：

数据部分：修改/新增数据生成模块，产生新问题实例数据结构。确保解表示和约束检查都针对新问题。

评估函数：调整适应度计算，反映新问题的优化目标。

策略模块：可能需要调整移除/修复策略逻辑。例如在调度问题中，移除可能涉及连续时间段任务，修复涉及资源重新分配等。可以在现有模块基础上修改，也可以重写更贴合新问题的策略模块。

DRL模块：若状态/动作空间变化，需要修改 DRL Agent 的输入特征提取和动作定义。可能还需重新训练模型。

配置：添加新问题特有参数（如机器数、时间窗宽度等）到配置结构中，并在代码中解析使用。

总体而言，本框架的核心遗传+局部搜索循环是通用的，移除/重插思想也适用广泛优化问题。扩展新问题主要在于数据和算子实现的变化，框架提供的计时、日志、结构化配置等机制可继续沿用，减少重复工作。

4. 调整算法参数和模块

并行加速：对于非常耗时的场景，可考虑并行评估适应度或并行执行局部搜索。扩展实现上，可引入多线程或多进程，将种群个体分批处理。但要注意Python GIL和数据同步问题。也可以考虑将关键计算移至Numba/C++提高速度。

混合策略：目前每次运行使用单一移除策略。若想实现自适应混合（类似ALNS自适应选择不同算子），可：

在每代中随机或根据表现选用不同策略。例如增加一个策略选择模块，根据前几次移除效果调整选择概率。

这需要修改HEA核心，在局部搜索调用前决定策略（或调用多个策略比较取最好）。

由于复杂度较高，建议先确保各单一策略效果再尝试混合，并仔细设计评分机制。

终止条件：框架默认为迭代到设定代数停止。可扩展为基于时间终止（在配置中加时间上限参数），或基于目标值阈值停止（如找到成本<=X即停）。实现上在主循环每代检查相应条件退出。

多次独立运行：为了获取统计结果，可以扩展程序支持一次运行进行多次独立实验取平均。例如配置一个 repeat: 5 参数，则程序自动重复生成新随机实例运行5次，输出平均结果。这需要在主流程外包一层循环，并汇总结果。在研究报告中经常用得到此功能。

结果解释与验证

扩展或调整后，建议通过小规模实例验证算法正确性：

比较修改前后算法在已知小例子上的结果，确认无约束违规，新策略逻辑符合预期。

查看日志确保新的模块按预期被调用、参数生效（可临时加入DEBUG日志打印内部信息辅助验证）。

使用 Timing 机制评估扩展对性能的影响，例如并行实现是否降低单次迭代时间。

当确认正确后，再投入大规模实验并分析结果改进之处。